{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 07: Predictive Models\n",
    "\n",
    "We now turn to a discussion of predictive models, a topic that is directly\n",
    "important for understand how images are used in AI and algorithmic decision\n",
    "making. It is also crutial for building a deeper understanding of image\n",
    "collections through extract features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We need to load the modules within each notebook. Here, we load the\n",
    "same set as in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "import urllib\n",
    "\n",
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cats and dogs\n",
    "\n",
    "We will now look at a different kind of visual dataset, consisting of images\n",
    "of cats and dogs. Here is the associated metadata (we really only have one\n",
    "piece of information for each image):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join(\"..\", \"data\", \"catdog.csv\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look a few of these images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "idx = np.random.permutation(range(len(df)))[:15]\n",
    "\n",
    "for ind, i in enumerate(idx):\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    plt.subplot(5, 3, ind + 1)\n",
    "\n",
    "    img = imread(join('..', 'images', 'catdog', df.filename[i]))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How easy is it for you to tell whether the image is of a cat or a dog?\n",
    "How might we go about teaching the computer to learn the difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features for learning a model\n",
    "\n",
    "Much like our exploratory work, we need to extract features from images in order to\n",
    "build predictive models. We will start with two relatively simple numeric features\n",
    "from each image: the average value and the average saturation. Let's built a matrix\n",
    "of these features now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(df), 2))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    img = imread(join(\"..\", \"images\", \"catdog\", df.filename[i]))\n",
    "    img_hsv = matplotlib.colors.rgb_to_hsv(img)\n",
    "    X[i, 0] = np.mean(img_hsv[:, :, 1])\n",
    "    X[i, 1] = np.mean(img_hsv[:, :, 2])\n",
    "    if i % 25 == 0:\n",
    "        print(\"Done with {0:d} of {1:d}\".format(i, len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also build an array that is equal to 0 for cats and 1 for dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.int32(df.animal.values == \"dog\")\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and evaluating a model for predictive learning\n",
    "\n",
    "### Linear regression\n",
    "\n",
    "We are now going to use the sklearn module to build predictive models from\n",
    "the dataset. We will start with a relatively simply model: a linear regression.\n",
    "\n",
    "The sklearn module has a consistent format for producing models. You start \n",
    "by creating an empty model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the dataset to *fit* the model to the data. This uses patterns seen\n",
    "in the data to distinguish between cats and dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our regression model makes a predict according to:\n",
    "\n",
    "    prediction = a + b * avg_saturation + c * avg_value\n",
    "    \n",
    "The model used the data to determine the best parameters\n",
    "for the numbers a, b, and c. We can see them here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does the model do at predicting which images are cats and which\n",
    "images are dogs? Let's see all of the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers are not exactly zero or one, so to compare we need to round to the\n",
    "closest integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.int32(pred > 0.5)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the model using a number of functions from the sklearn\n",
    "metrics submodule. Here is the accuracy, just the percentage of predictions\n",
    "that were correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(y, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll often also hear about precision and recall. Precision tells\n",
    "us what percentage of those images classified as a dog were actually\n",
    "dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.precision_score(y, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall shows the percentage of dogs that we correctly determined were dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.recall_score(y, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you think of a way to make the precision really high without doing much\n",
    "work? How about the recall? \n",
    "\n",
    "A popular metric that balances the recall and precision is the F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.f1_score(y, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a ROC curve shows well we would do if we used a cut-off\n",
    "score other than 0.5. They are very common in CS papers and it helps\n",
    "to be able to understand them if you want to look at new advances\n",
    "in computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y, pred)\n",
    "plt.plot(fpr, tpr, 'b')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can summarize the ROC curve with a measurment called the AUC:\n",
    "area under the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbors\n",
    "\n",
    "Let's try a different model: k-nearest neighbors. Each image is classified\n",
    "according to the other images that are closest to it. The syntax is almost \n",
    "exactly the same, but the predictions directly return predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors\n",
    "\n",
    "model = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "#model.fit(X, y)\n",
    "#yhat = model.predict(X)\n",
    "#yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to do much better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(y, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there's a bit of a problem here. Can you figure out\n",
    "why this is not a very fair comparision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the data\n",
    "\n",
    "Let's split the data into two groups. This is made fairly easy with the sklearn\n",
    "module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will train the model with the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But do predictions on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "sklearn.metrics.accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we see there there is not much improvement compared to the linear\n",
    "regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding features\n",
    "\n",
    "We won't be able to get a very good classification algorithm using only the\n",
    "two features we have started with. We'll need something more than just a fancy\n",
    "model. Let's go back to the histogram features from the last set of notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(df), 50))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    img = imread(join(\"..\", \"images\", \"catdog\", df.filename[i]))\n",
    "    img_hsv = matplotlib.colors.rgb_to_hsv(img)\n",
    "    img_hsv[img_hsv[:, :, 1] < 0.2, 0] = img_hsv[img_hsv[:, :, 1] < 0.2, 2] + 1\n",
    "    X[i, :] = np.histogram(img_hsv[:, :, 0].flatten(), bins=50, range=(0, 2))[0]\n",
    "    if i % 25 == 0:\n",
    "        print(\"Done with {0:d} of {1:d}\".format(i, len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make a training and testing split one more time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, build a model from the data, testing the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "yhat = np.int32(pred > 0.5)\n",
    "sklearn.metrics.accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should find that the accuracy is higher than it was before.\n",
    "Better data makes better models. Notice that the ROC curve also\n",
    "looks better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, 'b')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can try this with the nearest neighbors model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "sklearn.metrics.accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to change the numebr of neighbors to improve the model. You should\n",
    "be able to get something similar to the linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
