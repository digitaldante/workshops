{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 14: Face Detection\n",
    "\n",
    "We extend deep learning models to deal with a specific type of object detection:\n",
    "the localization and identification of faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "import urllib\n",
    "\n",
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dlib: A frustrating library for face detection\n",
    "\n",
    "We need a few new libraries today. You should be able to \n",
    "install these with:\n",
    "\n",
    "    pip install cmake\n",
    "    pip install dlib\n",
    "    pip install face_recognition\n",
    "    \n",
    "Load in the face_recognition library with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition as fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bewitched\n",
    "\n",
    "Let's load and look at the the bewitch corpus. It contains still images\n",
    "from two episodes of the sitcom Bewitched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join(\"..\", \"data\", \"bewitched.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are struggling with installing these, we are happy to assist. You'll be able to follow\n",
    "along with keras, but will not be able to apply the techniques you learned today to new datasets\n",
    "without it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face detection\n",
    "\n",
    "As an example of what this new corpus looks like, here is an image of Darrin and Samantha\n",
    "in their living room at the start of the episode \"Witches and Warlocks Are my Favorite\n",
    "Things\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = join('..', 'images', 'bewitched', df.filename[200])\n",
    "img = imread(img_path)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two faces in this image, which we can detect using the face_recognition\n",
    "algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = fr.face_locations(img, 1, model=\"cnn\")\n",
    "    \n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output indicates that two faces are detected, and the numbers gives the\n",
    "coordinates for the faces known as *bounding boxes*. We can plot them in Python\n",
    "with the following snippet of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "plt.imshow(img)\n",
    "n, m, d = img.shape\n",
    "for face in faces:\n",
    "    rect = plt.Rectangle((face[3], face[0]), face[2] - face[0], face[1] - face[3],\n",
    "                         edgecolor='orange', linewidth=2, facecolor='none')\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as hoped, the detected faces line up with the two characters in the frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face identification\n",
    "\n",
    "In addition to detected *where* a face is, we also want to determine *who* the face\n",
    "belongs to. In order to do this, we again make use of a pre-trained neural network\n",
    "that returns a sequence of numbers. Just as with image similarity, we assume that\n",
    "faces of the same person are identified with similar sequences of numbers.\n",
    "\n",
    "To illustrate how this works, lets take a set of four faces from Bewitched. The first\n",
    "two are of the same character (Samantha) but the second two are of of Larry and Darrin,\n",
    "respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "for id, index in enumerate([145, 300, 420, 707]):\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    plt.subplot(1, 4, id + 1)\n",
    "\n",
    "    img_path = join('..', 'images', 'bewitched', df.filename[index])\n",
    "    img = imread(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the 128-dimension number associated with each face using the function\n",
    "`fr.face_encodings` applied to each face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = []\n",
    "for id, index in enumerate([300, 145, 420, 707]):\n",
    "    img_path = join('..', 'images', 'bewitched', df.filename[index])\n",
    "    img = imread(img_path)\n",
    "\n",
    "    f = fr.face_locations(img, 1, model=\"cnn\")\n",
    "    e = fr.face_encodings(img, known_face_locations=[f[0]])\n",
    "    embed.append(e[0])\n",
    "    \n",
    "embed = np.array(embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the first image of Samantha as a baseline, look at how close each of the other three\n",
    "images are to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((embed - embed[0, :])**2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other image of Samantha is just 0.202 away but the images of the two male characters\n",
    "are 0.709 and 0.710 away. Using a cut-off (around 0.35 works well), we can identify images\n",
    "of Samantha with a reasonably high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faces at scale\n",
    "\n",
    "Finally, let's apply our face detection algorithm of the entire corpus of Bewitched\n",
    "iamges. The face detect is fairly slow (it took about 30 minutes on a small MacBook\n",
    "to do all of the images), so we recommend you set `process_new` to `False` and load\n",
    "the faces in from the save file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_new = False\n",
    "\n",
    "if process_new:\n",
    "    embed = []; output = []\n",
    "    corpus = pd.read_csv(join(\"meta\", cn + \".csv\"))\n",
    "    for index, row in corpus.iterrows():\n",
    "        img_path = join('images', cn, row['filename'])\n",
    "        img = sp.misc.imread(img_path)\n",
    "        faces = fr.face_locations(img, 1, model=\"cnn\")\n",
    "        output.append(faces)\n",
    "        enc = fr.face_encodings(img, known_face_locations=faces)\n",
    "        embed.append(enc)\n",
    "else:\n",
    "    faces = np.load(join(\"..\", \"data\", \"bewitched_faces.npy\"))\n",
    "    embed = np.load(join(\"..\", \"data\", \"bewitched_embed.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare each of the embeddings to first image used in Step 13, storing the\n",
    "distance in the array `samantha_dist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samantha = embed[145][0]\n",
    "\n",
    "samantha_dist = np.ones(len(df))\n",
    "for item in range(embed.shape[0]):\n",
    "    for em in embed[item]:\n",
    "        samantha_dist[item] = np.sum((samantha - em)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cut-off of 0.35, how many frames contain an image of Samantha?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(samantha_dist < 0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a total of 119 images show a definitive image of Samantha. Using a similar\n",
    "block of code to the similarity metrics used throughout these notes, what images contain\n",
    "the most similar Samantha faces to our prototype image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 24))\n",
    "\n",
    "sam_index = np.argsort(samantha_dist).tolist()\n",
    "for ind, i in enumerate(sam_index[:24]):\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    plt.subplot(8, 3, ind + 1)\n",
    "\n",
    "    img_path = join('..', 'images', 'bewitched', df.filename[i])\n",
    "    img = imread(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like our prototype, almost all of these indicates a relatively large view of Samantha looking\n",
    "straight at the camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, use image 707 as a baseline for Darrin and compute a darrin_distance metric for\n",
    "each image**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darrin = embed[707][0]\n",
    "\n",
    "darrin_dist = np.ones(len(df))\n",
    "for item in range(embed.shape[0]):\n",
    "    for em in embed[item]:\n",
    "        darrin_dist[item] = np.sum((darrin - em)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then, display the top 24 images of Darrin.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 24))\n",
    "\n",
    "darrin_index = np.argsort(darrin_dist).tolist()\n",
    "for ind, i in enumerate(darrin_index[:24]):\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    plt.subplot(8, 3, ind + 1)\n",
    "\n",
    "    img_path = join('..', 'images', 'bewitched', df.filename[i])\n",
    "    img = imread(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do these compare to those of Samantha?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
