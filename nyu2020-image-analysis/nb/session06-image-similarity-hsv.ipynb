{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 06: Image Similarity with HSV\n",
    "\n",
    "We use our new HSV values to show how images are similar based on their\n",
    "hue, saturation, and value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We need to load the modules within each notebook. Here, we load the\n",
    "same set as in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiArt corpus\n",
    "\n",
    "We are going to look now at a larger corpus of images from the WikiArt collection.\n",
    "It consists of work from three artists. Here's the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(join(\"..\", \"data\", \"wikiart.csv\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look a few of these images. Adjust the following code by choosing a\n",
    "different number for 0 to 643:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(join(\"..\", \"images\", \"wikiart\", df.filename[10]))\n",
    "\n",
    "img_hsv = matplotlib.colors.rgb_to_hsv(img)          # convert to hsv space\n",
    "img_new = img_hsv.copy()                             # make a copy of the image\n",
    "img_new[:, :, 1] = 1                                 # set saturation to 1\n",
    "img_new[:, :, 2] = 1                                 # set value to 1\n",
    "\n",
    "img_new[img_hsv[:, :, 1] < 0.2, 1] = 0               # set saturation to 0 (white) if unsaturated \n",
    "img_new[img_hsv[:, :, 1] < 0.2, 1] = 0               # set saturation to 0 (white) if unsaturated\n",
    "\n",
    "img_new_rgb = matplotlib.colors.hsv_to_rgb(img_new)  # convert back to rgb to print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)         # show the original image\n",
    "plt.figure(2)           # start a new figure\n",
    "plt.imshow(img_new_rgb) # show the hue version of image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating the corpus\n",
    "\n",
    "Okay, now let's try to actually start using the entire corpus. We will\n",
    "compute the histograph counts for each of the hue for every single image\n",
    "in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(df), 30))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    img = imread(join(\"..\", \"images\", \"wikiart\", df.filename[i]))\n",
    "    img_hsv = matplotlib.colors.rgb_to_hsv(img)\n",
    "    img_hsv[img_hsv[:, :, 1] < 0.2, 0] = img_hsv[img_hsv[:, :, 1] < 0.2, 2] + 1\n",
    "    X[i, :] = np.histogram(img_hsv[:, :, 0].flatten(), bins=30, range=(0, 2))[0]\n",
    "    if i % 25 == 0:\n",
    "        print(\"Done with {0:d} of {1:d}\".format(i, len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the first few rows of these numbers here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at images that are closest in terms of the hue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "ref_img_num = 0  # change this number!\n",
    "\n",
    "print(df.iloc[ref_img_num])\n",
    "idx = np.argsort(np.sum(np.abs(X - X[ref_img_num, :]), axis=1))[:9]\n",
    "\n",
    "for ind, i in enumerate(idx):\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    plt.subplot(3, 3, ind + 1)\n",
    "\n",
    "    img = imread(join('..', 'images', 'wikiart', df.filename[i]))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "We are now, finally, ready to move into the second part of the course. We have\n",
    "seen how features extracted from images let us explore a collection, but we need\n",
    "better features to capture more interesting things about the images... for that\n",
    "we need to digress a bit and talk about machine learning and deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"../\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
