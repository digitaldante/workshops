{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 11: Transfer Learning\n",
    "\n",
    "Let's see how to use transfer learning to improve our cat/dog model\n",
    "and to do better image similarity metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "import urllib\n",
    "\n",
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading a particular neural network model called VGG19. It\n",
    "contains 25 layers and over 143 million parameters. The code below reads\n",
    "in the entire model and prints out it structure (unless keras is unavailable,\n",
    "in which case a saved version of the model is printed just for reference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_full = VGG19(weights='imagenet')\n",
    "vgg19_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = join(\"..\", \"images\", \"test\", \"dog.jpg\")\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = vgg19_full.predict(x)\n",
    "for pred in decode_predictions(y)[0]:\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "The VGG19 model was constructed in order to predict the objects present in an image,\n",
    "but there is a lot more that we can do with the model. The amazing property of deep\n",
    "learning is that the intermediate results in the neural network operate by detecting\n",
    "lower-level features of the image. For example, the first few detect edges and textures,\n",
    "the next few by understanding shapes, and the latter ones put these together to detect\n",
    "objects. This is incredibly useful because it means that looking at the intermediate\n",
    "outputs can tell us something interesting about the images beyond just the 1000\n",
    "predicted categories.\n",
    "\n",
    "Assuming the keras module is installed, we will create a new model that outputs the\n",
    "second-to-last output of the model. The prediction of this contains 4096 dimensions.\n",
    "These do not correspond directly to categories, but (in theory) images containing\n",
    "similar objects should have similar 4096-dimensional values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_fc2 = Model(inputs=vgg19_full.input, outputs=vgg19_full.get_layer('fc2').output)\n",
    "vgg_fc2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, we will apply this to the dog image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = vgg_fc2.predict(x, verbose=True)\n",
    "embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers on their own do not really mean anything specific, but\n",
    "they do serve as abstract features that we could use in a next \n",
    "processing step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying transfer learning to cats and dogs\n",
    "\n",
    "Let us now apply the transfer learning algorithm to the cats and\n",
    "dogs dataset. Note that this may take a while to run (around 10-15\n",
    "minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join(\"..\", \"data\", \"catdog.csv\"))\n",
    "y = np.int32(df.animal.values == \"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.zeros((len(df), 224, 224, 3))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    img_path = join(\"..\", \"images\", \"catdog\", df.filename[i])\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    output[i, :, :, :] = x\n",
    "    if (i % 100) == 0:\n",
    "        print(\"Loaded image {0:03d}\".format(i))\n",
    "\n",
    "output = preprocess_input(output)\n",
    "img_embed = vgg_fc2.predict(output, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the output of the model, and make sure you understand why this\n",
    "image size makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding model\n",
    "\n",
    "We can use the embedding features to build a predictive model for the\n",
    "dogs and cats. Let's see how well this works. Note that we no longer\n",
    "need convolutions because the input is no longer raw image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(img_embed.shape[1],), activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(units=2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01, momentum=0.8, decay=0.0, nesterov=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(img_embed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=32,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict_classes(X_test)\n",
    "sklearn.metrics.accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the predictive model is significantly better through the\n",
    "use of transfer learning. And here are the few remaining mistakes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "yhat = model.predict_classes(img_embed)\n",
    "\n",
    "idx = np.where(yhat != y)[0][:15]\n",
    "\n",
    "for ind, i in enumerate(idx):\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    plt.subplot(5, 3, ind + 1)\n",
    "\n",
    "    img = imread(join('..', 'images', 'catdog', df.filename[i]))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation system\n",
    "\n",
    "Another thing that we can do with deep learning embeddings is to use\n",
    "the features to find images that are close to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "ref_img_num = 750  # change this number!\n",
    "\n",
    "print(df.iloc[ref_img_num])\n",
    "idx = np.argsort(np.sum(np.abs(img_embed - img_embed[ref_img_num, :])**2, axis=1))[:9]\n",
    "\n",
    "for ind, i in enumerate(idx):\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    plt.subplot(3, 3, ind + 1)\n",
    "\n",
    "    img = imread(join('..', 'images', 'catdog', df.filename[i]))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try some different numbers and see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
