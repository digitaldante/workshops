{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 12: Embedding the Corpora\n",
    "\n",
    "These notes embed a corpus of images using the VGG16 corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "import urllib\n",
    "\n",
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "We start by loading the VGG19 model and extracting the penultimate layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/taylor/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "vgg19_full = VGG19(weights='imagenet')\n",
    "vgg_fc2 = Model(inputs=vgg19_full.input, outputs=vgg19_full.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to select a corpus and apply the model. Here, we are going to\n",
    "define a function that wraps up the functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embed(corpus_name):\n",
    "\n",
    "    df = pd.read_csv(join(\"..\", \"data\", corpus_name + \".csv\"))\n",
    "    output = np.zeros((len(df), 224, 224, 3))\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        img_path = join(\"..\", \"images\", corpus_name, df.filename[i])\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        output[i, :, :, :] = x\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Loaded image {0:03d}\".format(i))\n",
    "\n",
    "    output = preprocess_input(output)\n",
    "    img_embed = vgg_fc2.predict(output, verbose=True)\n",
    "    \n",
    "    np.save(join(\"..\", \"data\", corpus_name + \"_vgg19_fc2.npy\"), img_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply this to the example corpus, which is relatively small and should\n",
    "not take very long to embed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embed(\"example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look in your data directory, you should see a file called \"example_vgg19_fc2.npy\".\n",
    "We can read this back into python using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(join(\"..\", \"data\", \"example_vgg19_fc2.npy\"))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over the data\n",
    "\n",
    "As you saw in the last session, it can take a while to embed a corpus\n",
    "using a large neural network. Here is the code that would create embeddings\n",
    "for the three datasets that we will look at in the next set of notes. We\n",
    "have already run them and can just distribute the npy files, but its\n",
    "useful to have this code if you want to run a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_embed(\"wikiart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation system\n",
    "\n",
    "Now that we have the embeddings, we can build a similarity system similar\n",
    "to the one that used with hue, saturation, and value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img_num = 1       # change this number!\n",
    "\n",
    "corpus_name = \"wikiart\"\n",
    "df = pd.read_csv(join(\"..\", \"data\", corpus_name + \".csv\"))\n",
    "X = np.load(join(\"..\", \"data\", corpus_name + \"_vgg19_fc2.npy\"))\n",
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "print(df.iloc[ref_img_num])\n",
    "idx = np.argsort(np.sum(np.abs(X - X[ref_img_num, :])**2, axis=1))[:9]\n",
    "\n",
    "for ind, i in enumerate(idx):\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    plt.subplot(3, 3, ind + 1)\n",
    "\n",
    "    img = imread(join('..', 'images', corpus_name, df.filename[i]))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try some different numbers and see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
